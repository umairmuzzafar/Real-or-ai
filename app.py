import streamlit as st
import torch
from transformers import pipeline
import sys

# Set page config first
st.set_page_config(
    page_title="Real or AI",
    page_icon="üîç",
    layout="wide"
)

st.title("üîç Real or AI")
st.write("Detect if text was written by a human or AI")

# Simple model loading with error handling
@st.cache_resource
def load_model():
    try:
        # Using a smaller model
        model_name = "facebook/bart-large-mnli"
        classifier = pipeline("zero-shot-classification", 
                            model=model_name, 
                            device=0 if torch.cuda.is_available() else -1)
        return classifier
    except Exception as e:
        st.error(f"Error loading model: {str(e)}")
        return None

# Load model at startup
classifier = load_model()

# Main UI
text = st.text_area("Enter text to analyze (minimum 50 characters):", height=200)

if st.button("Analyze"):
    if not text.strip():
        st.warning("Please enter some text to analyze")
    elif len(text.strip()) < 50:
        st.warning("Please enter at least 50 characters for accurate analysis")
    else:
        with st.spinner("Analyzing text..."):
            try:
                if classifier is None:
                    st.error("Model failed to load. Please refresh the page.")
                else:
                    # Using zero-shot classification
                    candidate_labels = ["human-written", "AI-generated"]
                    result = classifier(text, candidate_labels)
                    
                    # Get scores
                    human_score = result["scores"][result["labels"].index("human-written")] * 100
                    ai_score = result["scores"][result["labels"].index("AI-generated")] * 100
                    
                    # Display results
                    st.subheader("Results")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Human", f"{human_score:.1f}%")
                    with col2:
                        st.metric("AI", f"{ai_score:.1f}%")
                    
                    if human_score > ai_score:
                        st.success("This text is likely human-written")
                    else:
                        st.warning("This text is likely AI-generated")
                        
            except Exception as e:
                st.error(f"Error during analysis: {str(e)}")
                st.error("Please try again with different text")

# Add some info
st.sidebar.markdown("""
### About
This tool helps detect if text was written by a human or generated by AI.

### How it works
- Uses a lightweight BART model for analysis
- Analyzes text patterns and structures
- Provides a confidence score for both human and AI
""")
